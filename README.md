# Tokenizer and Splitter

Consist of tokenizer and splitter programs for Russian. It has built-in normalization of a text.
To start: change the name 'test.txt' in 'f = codecs.open('test.txt', 'r', 'utf-8-sig')' in the fifth line to the name of your file and put the file in the same directory where Tok&Split.py is.
In this repository you can find tokenizer and splitter that was made as a HSE course project and tokenizer that is used for Geekrya project by ABBYY.
